---
title: Insert title here
key: d11273f1ad194664904c6212fe921d45

---
## Fitting ARMA models

```yaml
type: "TitleSlide"
key: "34934da233"
```

`@lower_third`

name: James Fulton
title: Climate Informatics Researcher, University of Edinburgh


`@script`
Now we know more about AR, MA and ARMA models in this chapter we will learn how to generate synthetic data and fit these models


---
## Generating Time Series Data

```yaml
type: "FullSlide"
key: "fb00859de8"
center_content: false
```

`@part1`
```python
from statsmodels.tsa.arima_process import arma_generate_sample
arma_generate_sample(ar, ma, nsample, sigma=1)
```{{1}}

```python
import numpy as np
ar_coeffs = np.array([0.5])
ma_coeffs = np.array([])
```{{2}}

```python
ar = np.hstack([1, -ar_coeffs])
ma = np.hstack([1,  ma_coeffs])
```{{3}}


`@script`
Statsmodels has great an inbuilt function which will generate AR, MA or ARMA synthetic data. This is the arma_generate_sample function which import here. Into this function we need to pass ar (autoregressive coefficients), ma (moving average coefficients), nsamples (the number of samples to generate) and sigma (the standard deviation of the noise)

Here we will generate data which has a lag-one autoregressive coefficient of 0.5 and no moving average coefficients. This equates to a AR(1) model. To do this we make a numpy array with a single element of 0.5 in it for the autoregressive coefficients and an empty numpy array for the moving average coefficients. We need to give the generator function both.

There are two things we need to be careful of when trying to use this function. 

The first is that we need to specify the lag 0 coefficient of MA and AR. You will almost always set this to 1 in practice and the situations where you won't are beyond the scope of this course.

The second thing is that the arma_generate_sample requires you to give it the negative of the autoregressive coefficients for lag greater than 1. 

We will use the numpy hstack function here to add the lag 1 coefficients to ar and ma and make sure we are passing the minus of the ar coefficients.


---
## Generating Time Series Data

```yaml
type: "FullSlide"
key: "734c4219ea"
```

`@part1`
```python
nsample = 100
sigma=1

data = arma_generate_sample(ar, ma, nsample, sigma=sigma)
```

```python
array([ 0.05185635, -0.44311913, -1.05776731, -0.03332579, -0.68884263,
       -0.26902862,  0.98686746,  0.27028874,  0.76555383, ...])
```{{2}}


`@script`
Finally, we will choose 100 samples and the noise standard deviation of 1 and generate some data!

The data we generate is a numpy array of values. If we plot this we can see that it behaves like we would expect


---
## Generating Time Series Data

```yaml
type: "FullSlide"
key: "1794b225dc"
disable_transition: true
```

`@part1`
```python
nsample = 100
sigma=1

data = arma_generate_sample(ar, ma, nsample, sigma=sigma)
```

![](https://assets.datacamp.com/production/repositories/4399/datasets/3d69f249f72d221f9ec968b3174d73dda974f350/raw_generated_data.png)


`@script`
Great, we have generated some time series data, except we are missing one finally ingredient. The actual time of each measurement. It would be possible to continue without this component, but it isn't very realistic, in the wild you will always have time stamps along with each measurement, so lets make up some time stamps to go along with this data


---
## Adding Time Stamps

```yaml
type: "FullSlide"
key: "b1120206c7"
```

`@part1`
```python
import pandas as pd
dates = pd.date_range(start='2015-01-01', freq='D', periods=nsample)```

```python
df = pd.DataFrame(data, index=dates, columns=['time series'])
```{{1}}

```python
            time series
2015-01-01     0.051856
2015-01-02    -0.443119
2015-01-03    -1.057767
2015-01-04    -0.033326
2015-01-05    -0.688843
...
```{{2}}


`@script`
We use the pandas package to generate some time data. Using the pandas.date_range package we can generate regular timestamps to attach to each of our sythetic data points. 

Here we specify the start time as the 1st jan 2015, we specify the frequency as 'D' for daily and we make the same number of date stamps as we have datapoints

Next we will combine our synthetic data and timestamps in a pandas dataframe, which is how you will usually hold your data

Using pandas we pass in our data giving it the column name 'time series' and we pass in our dates as indices for the data.


---
## Adding Time Stamps

```yaml
type: "FullSlide"
key: "bd8592f3fc"
disable_transition: true
```

`@part1`
```python
import pandas as pd
dates = pd.date_range(start='2015-01-01', freq='D', periods=nsample)```

```python
df = pd.DataFrame(data, index=dates, columns=['time_series'])
```

![](https://assets.datacamp.com/production/repositories/4399/datasets/dcaf17246c2965d2ba8175436ec2b353dc44f704/pandas_generated_data.png)


`@script`
Great! We have now generated some data. Next we will use the statsmodels package to fit a model to this data! Let's go


---
## Fitting an AR model

```yaml
type: "FullSlide"
key: "293ab0de72"
```

`@part1`
```python
from statsmodels.tsa.arima_model import ARMA
ARMA(df, order=(p,q))
```

```python
model = ARMA(df, order=(1,0))
```{{1}}

```python
results = model.fit()
```{{2}}


`@script`
We will use the ARMA model from within the statsmodels package to fit the data that we created earlier. We import it from the model as so.

First we create the model object by passing it the data in dataframe df and the order. The order of the model is the number of lags we use in autoregression and moving average. Remember that the data we generated was from a simple an AR(1). Therefore p will be 1 and q will be 0 in this case.

Next we call the models fit method and assign the returned fitted model object to the variable results.

That's it! We have successfully generated synthetic AR data and fit a model to it!


---
## Fitting an AR model

```yaml
type: "FullSlide"
key: "ed82afe57d"
```

`@part1`
```python
results.summary().tables[1]
```

```python
=====================================================================================
                        coef    std err          z      P>|z|      [0.025      0.975]
-------------------------------------------------------------------------------------
const                 0.0725      0.209      0.347      0.729      -0.336       0.481
ar.L1.time_series     0.5737      0.083      6.908      0.000       0.411       0.736
=====================================================================================
```{{1}}


`@script`
We will explore the results object further in a later video but for now you can see in the bottom row of the results object table the fitted AR coefficient is 0.57 +- 0.08. This matches out input of 0.5 within one standard error


---
## Generating and Fitting More Complex Models

```yaml
type: "FullSlide"
key: "94f8e6b720"
```

`@part1`
```python
ar_coefs = np.array([0.5,  0.5])
ma_coefs = np.array([0.5, -0.5])
```

```python
ar = np.hstack([1, -ar_coefs])
ma = np.hstack([1,  ma_coefs])
data = arma_generate_sample(ar, ma, nsample, sigma=sigma)
```{{1}}


`@script`
We have now covered everything we need to generate and fit more general ARMA models. Here we generate an ARMA(2,2) model with 2 autoregressive lag coefficients and 2 moving average lag coefficients. We can repeat all the steps we used for the AR(1) data and generate this new dataset.


---
## Generating and Fitting More Complex Models

```yaml
type: "FullSlide"
key: "acdbecdc8e"
disable_transition: true
```

`@part1`
```python
ar_coefs = np.array([0.5,  0.5])
ma_coefs = np.array([0.5, -0.5])
```

![](https://assets.datacamp.com/production/repositories/4399/datasets/2a4d489b987ee091fce17adfb34b860c010325b8/complex_pandas_generated_data.png)


`@script`
We can see that this new dataset has regular peaks and troughs and is much closer to the real world datasets we have seen before.


---
## Generating and Fitting More Complex Models

```yaml
type: "FullSlide"
key: "ab58c81457"
```

`@part1`
```python
ar_coefs = np.array([0.5,  0.5])
ma_coefs = np.array([0.5, -0.5])
```

```python
model = ARMA(df, order=(2,2))
results = model.fit()
```
```python
print(results.summary().tables[1])
```{{1}}
```python
=====================================================================================
                        coef    std err          z      P>|z|      [0.025      0.975]
-------------------------------------------------------------------------------------
const                 3.9819      1.363      2.920      0.004       1.310       6.654
ar.L1.time_series     0.4545      0.035     13.063      0.000       0.386       0.523
ar.L2.time_series     0.5216      0.033     15.729      0.000       0.457       0.587
ma.L1.time_series     0.5510      0.036     15.141      0.000       0.480       0.622
ma.L2.time_series    -0.4490      0.036    -12.385      0.000      -0.520      -0.378
=====================================================================================
```{{2}}


`@script`
Just like before, we define the number of autoregressive and moving average lags and create a model object. This time we have 2 autoregressive lags and 3 moving average lags.

Then we fit the model and assign the returned results object to the variable results

Finally we print the model parameters from the results object. You can see that the two ar coefficients are close to the two ar coefficents we used to generate the data and that the 2 MA coefficients are also close in value to the 2 we used to generate the data.

You will use what we have learned here to generate your own ARMA data and fit your own ARMA models.


---
## Let's practice!

```yaml
type: "FinalSlide"
key: "8ca7b9d309"
```

`@script`
Lets start practicing!

